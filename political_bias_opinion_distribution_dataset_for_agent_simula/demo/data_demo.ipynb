{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Political Bias Opinion Dynamics Dataset Demo\n",
        "\n",
        "This notebook demonstrates the **cajcodes/political-bias** dataset, which provides political bias classifications on a 5-point scale. The data is ideal for agent-based opinion dynamics simulations.\n",
        "\n",
        "## Dataset Overview\n",
        "- **Source**: cajcodes/political-bias\n",
        "- **Scale**: 5-point (0=far_right to 4=far_left)\n",
        "- **Normalized Scale**: -1.0 to +1.0 (right to left)\n",
        "- **Categories**: far_right, right, center, left, far_left"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data\n",
        "\n",
        "Load the dataset from GitHub (or local fallback for development)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "# GitHub raw URL for the demo data\n",
        "GITHUB_DATA_URL = \"https://raw.githubusercontent.com/AMGrobelnik/ai-invention-e59d7b-perception-asymmetry-feedback-loop-how-d/main/data_exec_iter1_idx3/demo/demo_data.json\"\n",
        "LOCAL_DATA_PATH = Path(\"demo_data.json\")\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Load data from GitHub URL with local fallback.\"\"\"\n",
        "    # Try GitHub URL first\n",
        "    try:\n",
        "        with urllib.request.urlopen(GITHUB_DATA_URL, timeout=10) as response:\n",
        "            data = json.loads(response.read().decode('utf-8'))\n",
        "            print(f\"Loaded data from GitHub: {GITHUB_DATA_URL}\")\n",
        "            return data\n",
        "    except Exception as e:\n",
        "        print(f\"GitHub fetch failed ({e}), trying local file...\")\n",
        "    \n",
        "    # Fallback to local file\n",
        "    if LOCAL_DATA_PATH.exists():\n",
        "        with open(LOCAL_DATA_PATH, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "            print(f\"Loaded data from local file: {LOCAL_DATA_PATH}\")\n",
        "            return data\n",
        "    \n",
        "    raise FileNotFoundError(\"Could not load data from GitHub or local file\")\n",
        "\n",
        "# Load the dataset\n",
        "data = load_data()\n",
        "examples = data['examples']\n",
        "print(f\"\\nLoaded {len(examples)} examples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Explore Data Structure\n",
        "\n",
        "Examine the structure of individual examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display first example structure\n",
        "print(\"Example data structure:\")\n",
        "print(json.dumps(examples[0], indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract key fields for analysis\n",
        "statements = []\n",
        "opinion_scores = []\n",
        "bias_categories = []\n",
        "\n",
        "for ex in examples:\n",
        "    # Extract statement from input (remove the prompt prefix)\n",
        "    statement = ex['input'].replace('Classify the political bias of this statement: \"', '').rstrip('\"')\n",
        "    statements.append(statement)\n",
        "    opinion_scores.append(ex['context']['opinion_score'])\n",
        "    bias_categories.append(ex['context']['bias_category'])\n",
        "\n",
        "print(f\"Extracted {len(statements)} statements with opinion scores\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Analyze Distribution\n",
        "\n",
        "Examine the distribution of political bias categories and opinion scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Count bias categories\n",
        "category_counts = Counter(bias_categories)\n",
        "\n",
        "print(\"Bias Category Distribution:\")\n",
        "print(\"=\" * 40)\n",
        "for category in ['far_right', 'right', 'center', 'left', 'far_left']:\n",
        "    count = category_counts.get(category, 0)\n",
        "    bar = '*' * count\n",
        "    print(f\"{category:12} | {bar} ({count})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Opinion score statistics\n",
        "print(\"\\nOpinion Score Statistics:\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Min score:  {min(opinion_scores):.1f} (far right)\")\n",
        "print(f\"Max score:  {max(opinion_scores):.1f} (far left)\")\n",
        "print(f\"Mean score: {sum(opinion_scores)/len(opinion_scores):.2f}\")\n",
        "\n",
        "# Score distribution\n",
        "score_counts = Counter(opinion_scores)\n",
        "print(\"\\nScore Distribution:\")\n",
        "for score in sorted(score_counts.keys()):\n",
        "    count = score_counts[score]\n",
        "    bar = '*' * count\n",
        "    print(f\"{score:5.1f} | {bar} ({count})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Sample Statements by Category\n",
        "\n",
        "View example statements from each political bias category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group statements by category\n",
        "statements_by_category = {}\n",
        "for statement, category in zip(statements, bias_categories):\n",
        "    if category not in statements_by_category:\n",
        "        statements_by_category[category] = []\n",
        "    statements_by_category[category].append(statement)\n",
        "\n",
        "# Display one example from each category\n",
        "print(\"Sample Statements by Political Bias:\")\n",
        "print(\"=\" * 60)\n",
        "for category in ['far_right', 'right', 'center', 'left', 'far_left']:\n",
        "    if category in statements_by_category:\n",
        "        print(f\"\\n[{category.upper()}]\")\n",
        "        print(f\"  \\\"{statements_by_category[category][0]}\\\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Opinion Dynamics Simulation Potential\n",
        "\n",
        "This dataset is ideal for agent-based opinion dynamics models because:\n",
        "\n",
        "1. **Continuous Scale**: Opinion scores range from -1.0 to +1.0, enabling smooth opinion transitions\n",
        "2. **Multimodal Clustering**: Data naturally clusters into 5 distinct positions\n",
        "3. **Real-World Grounding**: Based on actual political statements with known biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple DataFrame-like summary for opinion dynamics\n",
        "print(\"Opinion Dynamics Data Summary:\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Index':<6} {'Score':>6} {'Category':<12} {'Statement (truncated)':<40}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for i, (score, cat, stmt) in enumerate(zip(opinion_scores, bias_categories, statements)):\n",
        "    truncated = stmt[:37] + \"...\" if len(stmt) > 40 else stmt\n",
        "    print(f\"{i:<6} {score:>6.1f} {cat:<12} {truncated:<40}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Export for Further Analysis\n",
        "\n",
        "Prepare data in formats suitable for opinion dynamics simulations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simplified dataset for opinion dynamics modeling\n",
        "opinion_data = [\n",
        "    {\n",
        "        'id': i,\n",
        "        'opinion_score': score,\n",
        "        'bias_category': cat,\n",
        "        'statement': stmt\n",
        "    }\n",
        "    for i, (score, cat, stmt) in enumerate(zip(opinion_scores, bias_categories, statements))\n",
        "]\n",
        "\n",
        "print(f\"Prepared {len(opinion_data)} records for opinion dynamics simulation\")\n",
        "print(\"\\nFirst 3 records:\")\n",
        "for record in opinion_data[:3]:\n",
        "    print(f\"  ID {record['id']}: score={record['opinion_score']:.1f}, category={record['bias_category']}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
